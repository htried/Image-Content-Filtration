{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88852ef7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-15 20:04:08.996616: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-07-15 20:04:08.996703: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "/home/htriedman/.local/lib/python3.7/site-packages/requests/__init__.py:91: RequestsDependencyWarning: urllib3 (1.26.8) or chardet (3.0.4) doesn't match a supported version!\n",
      "  RequestsDependencyWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.models import load_model\n",
    "from keras.applications.mobilenet import preprocess_input\n",
    "from keras.preprocessing.image import (\n",
    "    ImageDataGenerator,\n",
    "    img_to_array,\n",
    "    load_img\n",
    ")\n",
    "from keras import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "921ba9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 30\n",
    "dimension1 = dimension2 = 224\n",
    "test_dir = '/home/htriedman/nsfw_data_scraper/data/test'\n",
    "model = '/home/htriedman/Image-Content-Filtration/trained/hal-retraining.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56052fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_image(img):\n",
    "    # Converts image to RGB,\n",
    "    # resizes to 224X224 and\n",
    "    # reshapes it for the MobileNet V1 Model\n",
    "    if img.mode != \"RGB\":\n",
    "        img = img.convert(\"RGB\")\n",
    "    img = img.resize((224, 224))\n",
    "    img = img_to_array(img)\n",
    "    img = img.reshape((1, img.shape[0], img.shape[1], 3))\n",
    "    img = preprocess_input(img)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e48a62f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2333 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(dimension1, dimension2),\n",
    "    color_mode='rgb',\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c92bd14b",
   "metadata": {},
   "source": [
    "# Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a3ed37c3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-15 20:04:30.954834: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-07-15 20:04:30.955355: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-07-15 20:04:30.955377: W tensorflow/stream_executor/cuda/cuda_driver.cc:326] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-07-15 20:04:30.955411: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (stat1005): /proc/driver/nvidia/version does not exist\n",
      "2022-07-15 20:04:30.955737: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-07-15 20:04:30.962443: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n"
     ]
    }
   ],
   "source": [
    "model = load_model(model)\n",
    "model.compile(\n",
    "    metrics=[\n",
    "        metrics.CategoricalAccuracy(),\n",
    "        metrics.AUC(),\n",
    "        metrics.CategoricalCrossentropy()\n",
    "            ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e42d395b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-15 20:04:39.168214: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2022-07-15 20:04:39.192813: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2400045000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78/78 [==============================] - 354s 5s/step - loss: 0.0000e+00 - categorical_accuracy: 0.9498 - auc: 0.9703 - categorical_crossentropy: 0.3573\n",
      "overall loss: 0.0\n",
      "overall accuracy: 0.9546\n",
      "overall AUC: 0.9748\n",
      "overall categorical crossentropy: 0.3254348635673523\n"
     ]
    }
   ],
   "source": [
    "out = model.evaluate(test_generator)\n",
    "print(f\"overall loss: {out[0]}\")\n",
    "print(f\"overall accuracy: {out[1]:.4f}\")\n",
    "print(f\"overall AUC: {out[2]:.4f}\")\n",
    "print(f\"overall categorical crossentropy: {out[3]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "34afa210",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_imgs(file_dir, output_class):\n",
    "    imgs = []\n",
    "    for img in os.listdir(f\"{file_dir}/{output_class}\"):\n",
    "        img = os.path.join(f\"{file_dir}/{output_class}\", img)\n",
    "        img = load_img(img, target_size=(dimension1, dimension2))\n",
    "        img = img_to_array(img)\n",
    "        img = np.expand_dims(img, axis=0)\n",
    "        img = preprocess_input(img)\n",
    "        imgs.append(img)\n",
    "    return np.vstack(imgs)\n",
    "\n",
    "def class_metrics(file_dir, output_class, class_position):\n",
    "    cl = get_imgs(file_dir, output_class)\n",
    "    preds = model.predict(cl, batch_size=batch_size)\n",
    "    output = {}\n",
    "    for thresh in np.linspace(0.1, 0.9, num=9):\n",
    "        preds_rounded = [1 if i[class_position] > thresh else 0 for i in preds]\n",
    "        accuracy = sum(preds_rounded) / len(preds_rounded)\n",
    "        output[f\"accuracy_thresh_{round(thresh, 1)}\"] = accuracy\n",
    "        print(f\"{output_class} accuracy with threshold {round(thresh, 1)}: {accuracy:.4f}\")\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "806d0250",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nsfw accuracy with threshold 0.1: 0.9055\n",
      "nsfw accuracy with threshold 0.2: 0.8976\n",
      "nsfw accuracy with threshold 0.3: 0.8945\n",
      "nsfw accuracy with threshold 0.4: 0.8898\n",
      "nsfw accuracy with threshold 0.5: 0.8850\n",
      "nsfw accuracy with threshold 0.6: 0.8772\n",
      "nsfw accuracy with threshold 0.7: 0.8724\n",
      "nsfw accuracy with threshold 0.8: 0.8661\n",
      "nsfw accuracy with threshold 0.9: 0.8551\n"
     ]
    }
   ],
   "source": [
    "_ = class_metrics(test_dir, \"nsfw\", 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "479d07be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sfw accuracy with threshold 0.1: 0.9918\n",
      "sfw accuracy with threshold 0.2: 0.9900\n",
      "sfw accuracy with threshold 0.3: 0.9882\n",
      "sfw accuracy with threshold 0.4: 0.9847\n",
      "sfw accuracy with threshold 0.5: 0.9806\n",
      "sfw accuracy with threshold 0.6: 0.9782\n",
      "sfw accuracy with threshold 0.7: 0.9759\n",
      "sfw accuracy with threshold 0.8: 0.9723\n",
      "sfw accuracy with threshold 0.9: 0.9647\n"
     ]
    }
   ],
   "source": [
    "_ = class_metrics(test_dir, \"sfw\", 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1f3b4ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "nsfw = get_imgs(test_dir, 'nsfw')\n",
    "sfw = get_imgs(test_dir, 'sfw')\n",
    "nsfw_preds = model.predict(nsfw, batch_size=batch_size)\n",
    "sfw_preds = model.predict(sfw, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6bc855f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "with threshold 0.1:\n",
      "accuracy:\t0.9486\n",
      "\n",
      "confusion matrix:\n",
      "tp:\t575\tfn:\t60\n",
      "fp:\t60\ttn:\t1638\n",
      "\n",
      "fpr:\t\t0.0353\n",
      "fnr:\t\t0.0945\n",
      "precision:\t0.9055\n",
      "recall:\t\t0.9055\n",
      "f1:\t\t0.9055\n"
     ]
    }
   ],
   "source": [
    "# set threshold at which something is considered \"nsfw\"\n",
    "thresh = 0.1\n",
    "\n",
    "# cast to binary preds\n",
    "nsfw_preds_rounded = [1 if i[0] > thresh else 0 for i in nsfw_preds]\n",
    "sfw_preds_rounded = [1 if i[0] > thresh else 0 for i in sfw_preds]\n",
    "\n",
    "# calculate metrics\n",
    "tp = sum(nsfw_preds_rounded)\n",
    "tn = len(sfw_preds_rounded) - sum(sfw_preds_rounded)\n",
    "fp = sum(sfw_preds_rounded)\n",
    "fn = len(nsfw_preds_rounded) - sum(nsfw_preds_rounded)\n",
    "\n",
    "acc = (tp + tn) / (tp + tn + fp + fn)\n",
    "fpr = fp / (fp + tn)\n",
    "fnr = fn / (fn + tp)\n",
    "precision = tp / (tp + fp)\n",
    "recall = tp / (tp + fn)\n",
    "f1 = 2 * precision * recall / (precision + recall)\n",
    "\n",
    "# print results\n",
    "print(f\"with threshold {thresh}:\")\n",
    "print(f\"accuracy:\\t{acc:.4f}\")\n",
    "print(f\"\\nconfusion matrix:\\ntp:\\t{tp}\\tfn:\\t{fn}\\nfp:\\t{fp}\\ttn:\\t{tn}\\n\")\n",
    "print(f\"fpr:\\t\\t{fpr:.4f}\")\n",
    "print(f\"fnr:\\t\\t{fnr:.4f}\")\n",
    "print(f\"precision:\\t{precision:.4f}\")\n",
    "print(f\"recall:\\t\\t{recall:.4f}\")\n",
    "print(f\"f1:\\t\\t{f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a532db",
   "metadata": {},
   "source": [
    "# Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d22bcafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = '/home/htriedman/Image-Content-Filtration/trained/hal-retraining_run_2.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ad789eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(model)\n",
    "model.compile(\n",
    "    metrics=[\n",
    "        metrics.CategoricalAccuracy(),\n",
    "        metrics.AUC(),\n",
    "        metrics.CategoricalCrossentropy()\n",
    "            ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ba376501",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78/78 [==============================] - 323s 4s/step - loss: 0.0000e+00 - categorical_accuracy: 0.9613 - auc_1: 0.9772 - categorical_crossentropy: 0.4641\n",
      "overall loss: 0.0\n",
      "overall accuracy: 0.9623\n",
      "overall AUC: 0.9774\n",
      "overall categorical crossentropy: 0.4287799000740051\n"
     ]
    }
   ],
   "source": [
    "out = model.evaluate(test_generator)\n",
    "print(f\"overall loss: {out[0]}\")\n",
    "print(f\"overall accuracy: {out[1]:.4f}\")\n",
    "print(f\"overall AUC: {out[2]:.4f}\")\n",
    "print(f\"overall categorical crossentropy: {out[3]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b1ade138",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nsfw accuracy with threshold 0.1: 0.9087\n",
      "nsfw accuracy with threshold 0.2: 0.9071\n",
      "nsfw accuracy with threshold 0.3: 0.9008\n",
      "nsfw accuracy with threshold 0.4: 0.8929\n",
      "nsfw accuracy with threshold 0.5: 0.8850\n",
      "nsfw accuracy with threshold 0.6: 0.8835\n",
      "nsfw accuracy with threshold 0.7: 0.8787\n",
      "nsfw accuracy with threshold 0.8: 0.8772\n",
      "nsfw accuracy with threshold 0.9: 0.8646\n"
     ]
    }
   ],
   "source": [
    "_ = class_metrics(test_dir, \"nsfw\", 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ca9f473d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sfw accuracy with threshold 0.1: 0.9947\n",
      "sfw accuracy with threshold 0.2: 0.9918\n",
      "sfw accuracy with threshold 0.3: 0.9912\n",
      "sfw accuracy with threshold 0.4: 0.9912\n",
      "sfw accuracy with threshold 0.5: 0.9912\n",
      "sfw accuracy with threshold 0.6: 0.9870\n",
      "sfw accuracy with threshold 0.7: 0.9847\n",
      "sfw accuracy with threshold 0.8: 0.9806\n",
      "sfw accuracy with threshold 0.9: 0.9741\n"
     ]
    }
   ],
   "source": [
    "_ = class_metrics(test_dir, \"sfw\", 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3022d461",
   "metadata": {},
   "outputs": [],
   "source": [
    "nsfw = get_imgs(test_dir, 'nsfw')\n",
    "sfw = get_imgs(test_dir, 'sfw')\n",
    "nsfw_preds = model.predict(nsfw, batch_size=batch_size)\n",
    "sfw_preds = model.predict(sfw, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d7bff04b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "with threshold 0.1:\n",
      "accuracy:\t0.9563\n",
      "\n",
      "confusion matrix:\n",
      "tp:\t577\tfn:\t58\n",
      "fp:\t44\ttn:\t1654\n",
      "\n",
      "fpr:\t\t0.0259\n",
      "fnr:\t\t0.0913\n",
      "precision:\t0.9291\n",
      "recall:\t\t0.9087\n",
      "f1:\t\t0.9188\n"
     ]
    }
   ],
   "source": [
    "# set threshold at which something is considered \"nsfw\"\n",
    "thresh = 0.1\n",
    "\n",
    "# cast to binary preds\n",
    "nsfw_preds_rounded = [1 if i[0] > thresh else 0 for i in nsfw_preds]\n",
    "sfw_preds_rounded = [1 if i[0] > thresh else 0 for i in sfw_preds]\n",
    "\n",
    "# calculate metrics\n",
    "tp = sum(nsfw_preds_rounded)\n",
    "tn = len(sfw_preds_rounded) - sum(sfw_preds_rounded)\n",
    "fp = sum(sfw_preds_rounded)\n",
    "fn = len(nsfw_preds_rounded) - sum(nsfw_preds_rounded)\n",
    "\n",
    "acc = (tp + tn) / (tp + tn + fp + fn)\n",
    "fpr = fp / (fp + tn)\n",
    "fnr = fn / (fn + tp)\n",
    "precision = tp / (tp + fp)\n",
    "recall = tp / (tp + fn)\n",
    "f1 = 2 * precision * recall / (precision + recall)\n",
    "\n",
    "# print results\n",
    "print(f\"with threshold {thresh}:\")\n",
    "print(f\"accuracy:\\t{acc:.4f}\")\n",
    "print(f\"\\nconfusion matrix:\\ntp:\\t{tp}\\tfn:\\t{fn}\\nfp:\\t{fp}\\ttn:\\t{tn}\\n\")\n",
    "print(f\"fpr:\\t\\t{fpr:.4f}\")\n",
    "print(f\"fnr:\\t\\t{fnr:.4f}\")\n",
    "print(f\"precision:\\t{precision:.4f}\")\n",
    "print(f\"recall:\\t\\t{recall:.4f}\")\n",
    "print(f\"f1:\\t\\t{f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0e4b3d31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "false negatives (classified sfw, actually nsfw)\n",
      "38 08d1c166db27873f31ab0d75544beb268de70dd784df047a31480aa284871af0.jpg 0.0\n",
      "59 62b5cea8072b156a5573b40067c5bce986e385cc43b4021018c8d4585ec78ed8.jpg 0.007\n",
      "62 8db349406f4f3f99da8a239205d426a998a880b605d2281f470687ecc2d7c513.jpg 0.0\n",
      "65 f8c2064755efd025b56af03b918687c62c2b1f387f92521e6a820bf7c9621a9c.jpg 0.0\n",
      "69 f43dc1708304602da7d5c6a2f49fdddec41e53cf38f0a6eeb215b6e1f244667c.jpg 0.0\n",
      "80 b506624cb34b7468fcbe96444851156b00153adc55ff9dcc4b5d11938725a9d2.jpg 0.0\n",
      "86 f58c1ca866cee8b52c8745d447878a04a74f2f5f0c738d48c1ac7d89b9620616.jpg 0.0\n",
      "94 0e80bb01ec5aa85580348a102bbc1f2c518d3a1635ad9d32a1aaad4ee3776287.jpg 0.004\n",
      "104 e9eccc1af946ae15b75f3422faa97ed1ca4bf27034227e752a3108bb296e7c63.jpg 0.0\n",
      "106 db78c5d7883c4882e60434b94bd17e1b4b64c04624ab80c38721be57911a5107.jpg 0.0\n",
      "110 20fc63f1177e099960b15761e53acd8c0bcdea901d1f49706f86e5dee3d5a532.jpg 0.07\n",
      "114 cb27189a1ef4ba2779b2f4ed005cd428e6767151ec0b565b8d4ffe7e912f09d1.jpg 0.0\n",
      "125 49566f9a7f1fc9eafe3fd26fa24879398694fe727187f0c0e2c962657ed9ce8b.jpg 0.0\n",
      "136 96d44089a439d4e5c936cfc4697a03ec0fd3ac7fffedf0b848e3946260f559a5.jpg 0.0\n",
      "143 7864c6f82c312b511fc5112059929191f31101fa066394a778f16ec5d00b598b.jpg 0.0\n",
      "187 78f59ed742b693453f090d66713a85b63cc0226565b36c739ac268d6ae7985ef.jpg 0.0\n",
      "211 b08389f0bbf2899a441de1cfd135783ee3c351bbeaf4c7aa50e2b2fc5b51a62a.jpg 0.0\n",
      "214 14620498cd5664981caa4309ba3cd97785ea4614212e642dcd7f4c973a55be6b.jpg 0.0\n",
      "218 7eee6aeb80f12f02a166d02834bf2afee5ff24190193d60f74429fd23c8ba049.jpg 0.0\n",
      "221 ff3d7a60179ab9c52d52689a36bb66a81b8c4e83f120c703f931f13575d2205e.jpg 0.014\n",
      "223 358f742664c9789fabf2b9084c6ce2b5b7e94d6ecc82e5e185d21693ee63f60b.jpg 0.084\n",
      "228 fcf4ad4c9cbe334f30b36f2282fffe9df719bede9388fe54a9d071f07b68a42b.jpg 0.035\n",
      "240 7cbe30b3256a72db9a19fb781a1f04ab8e984cb56155a2e55911c9dc64242210.jpg 0.029\n",
      "248 00952278f9cfda28bef6d7f4d4dd7cd7904a7b2689f9f578224d8da6bb395d45.jpg 0.007\n",
      "251 7579822d44f99bf4b7c06f32f7ac93050578bc8fc099784581927cf264c62015.jpg 0.0\n",
      "260 00e7f04c7615ab320805ab82f8c5fa5a9802a52b0fe9cfd72c875a45425f3513.jpg 0.0\n",
      "268 b3f50fc3a8b4acb5c90e419cc7242bdd648ff617caded7ba0ed1006594de4802.jpg 0.0\n",
      "276 4dc53f9a2b06d81d733c8814b1e303366fea30050ceb8cbac1911d343eed3ca8.jpg 0.0\n",
      "296 cfd87a890fe507d9ed142b8dfb88800a1f51516e7f9ac33772389c9727c43e4b.jpg 0.0\n",
      "299 b14169673dc973893da898885ffd838762bab993a1cf5eac94059b17fbcb625c.jpg 0.0\n",
      "311 3653c3ca35f83c8d9733805fa0cf1ac3ae23985d241a9bb9cd1b435a47875817.jpg 0.0\n",
      "321 95fc6d619715ad8587e5e2e3309843c655ad76b074191d0772bf722c41496cee.jpg 0.011\n",
      "379 b5493f42d7f8703756358fa0b1bc04b44af4546447d8645c32bfb1f0819f9f8a.jpg 0.0\n",
      "383 9d5753f4612a4244346f87c80a4bacb632e08d70e8ca28ef079ccfe628d5cfd5.jpg 0.0\n",
      "391 4f2eec7a7e88e5263d95bec5f255a4b402155fe1c3c53c0bf3d4ffbde2b46b41.jpg 0.017\n",
      "412 9cafd8607c5bb4b336de2ae6d8e63f6fc661db8f9461b4d2caa8dd3cc473d7ba.jpg 0.074\n",
      "427 f18635521c80a1199ea76fd8b53af0c6ec5567a3ca4d73847fd37f70e9b4c715.jpg 0.01\n",
      "434 f660fc8a4fe602bc84019cce48f50fb664196f72312369e6ab195d8f8bcc5309.jpg 0.0\n",
      "456 2fb1980d31021ca741acf6553b428f0f681fc6b6487026cd874e55cc9da42ecf.jpg 0.0\n",
      "458 d19949bae9627c1d24b0b961d7a47aa7239c2516ed82d1134efd019bc0bd10bf.jpg 0.0\n",
      "460 9b1328fe9c9ad26106e8eeaba46e3f3eaae556562d005d1c2333390a70b003bb.jpg 0.084\n",
      "461 d1a79b9b269d4dc7d242d5ec17efa3a42b7cc83ef7b0aeb29db9e3c73ef061c7.jpg 0.005\n",
      "483 b5b8028be7e485b27ef362b4cab9e48df6aada10b167bb0ce548007bd1a353c9.jpg 0.0\n",
      "498 522c0b00539ac9f47b4e45e7651f19b1b760ea2762886cd6037e16f46de49d36.jpg 0.0\n",
      "510 e597b1b5445842ff43ad74b9a3d7080ebbe3d318d606e47cf18f206d85cfa95e.jpg 0.0\n",
      "522 c19aea84d7ee9387feaa4b19a1dc6b77aedb6a018333336ea6065ec45eef9803.jpg 0.0\n",
      "530 00fe949a7a3dd441fb65059289d34edd9d3f3ff2e069751ecabf4388afd41bda.jpg 0.005\n",
      "538 aea6375f9b580a7d4811e36f5fe8ad89bce80d35e3a2eff73be2a84211240636.jpg 0.0\n",
      "544 a9fd1d3a9332cf6426903bcd38d0fcea98277e3ede90911f429af3d7ebde409f.jpg 0.0\n",
      "548 50645f094ed9afcd22a7ebe67ad2e653c7deae95e5f984af7fdf20240d56c470.jpg 0.0\n",
      "550 e02dbbe3e7113a8d04d9c14f4d87a3e23c6e2e40592e4349ebdf926de171208b.jpg 0.017\n",
      "553 5bf75470da27d9ad2f2145804bca2de2914d4e5dd95f3945adf17864c870a2af.jpg 0.04\n",
      "557 f6499dfc33f8691d58ff3a0d17032cb55977f39bce0d1bb5a82b80347107277a.jpg 0.0\n",
      "575 d215cfcdc1f1d9ce4141a9a7f271d17e0813681b22a2de77a524fae6fb4a522d.jpg 0.0\n",
      "579 733ca8ae3b6fd64a9a084d8202f5f536595a6347b1894ef89821b4e2c9fb2440.jpg 0.0\n",
      "587 d6ab6a1ea2ff768a5a4b881bf5bf79833963e0ee65b2ccddddfdcea3b8640f2b.jpg 0.0\n",
      "591 306ac5307b33d988fcef54de20df0ec5784e4bfccde6be962f42cd0285552472.jpg 0.0\n",
      "620 811983d366bc72b14401a3b6b682d97c58a17fdb87add75a51f9a3c844082cb5.jpg 0.0\n",
      "\n",
      "false positives (classified nsfw, actually sfw)\n",
      "141 ad89ed093eda9117496c6bd3820aff0ff7111ef7d07efd9ddeaebbd1e96512e9.jpg 0.435\n",
      "150 2c60dd02aaadee949f3549d42c3c6d0627dbdde9d1a44af0939f443796ec0631.jpg 0.361\n",
      "179 fae4299e87bf23896a75d050fb1ec01f6fc6c7d4a8cbdafd7d8f921c1ff57faf.jpg 0.233\n",
      "181 82f5b4ef145e3145d5b5ae074e7e3f1319076ee588a23886c380abc838595e98.jpg 0.887\n",
      "207 b1b32057e58ca2e2f57a99c415ae03de57a1f8b3abf75e2fe992338e3c706b80.jpg 0.11\n",
      "221 c9938c6efb83dacb887e05ce82dd9f6a08404ec0dc518f5dcee16257babfb33f.jpg 0.313\n",
      "226 f4a62681d0cc7b1e827b2791c4291afe353defb463fee48b6cf1783ac691c98a.jpg 0.739\n",
      "259 4a8ebd3457fbc5486eb6939d2e22bb8523397e672068ecd7ad84ad212f9d1236.jpg 0.292\n",
      "301 03680e1582690ced310e948bcc6fc5e6eef61b7db4afd633c9efcb4d48744189.jpg 0.185\n",
      "348 6778de579e288caa6c6a0b2daf2a160bf4ea88b1c60feb9607ebcb5d901bb692.jpg 0.42\n",
      "391 bbbf51fee3a466a67b8824c5396b6097226caa83a0fb0a2a85f973384d63c569.jpg 0.107\n",
      "439 c043d19d90f7893928714a9a5cabbd3a0f9e8ec630b2d79ff3e8fceb997ac049.jpg 0.133\n",
      "485 7cf5168b816d581cce0937f49b14cc67f40efbeb4a51dd76137872be02cb4a5e.jpg 0.824\n",
      "582 8b06ab2f505f4fda5bcde9d5e12e0689343b54bd3a3579651a3c5ba2425a3914.jpg 0.265\n",
      "620 4816f7ed729a336ee21a89970056e10c3b4b8d533d50a0b128aaf02641737c58.jpg 0.846\n",
      "645 0c9fbb0b63ae7277e1a32bd8e433c601d62d099e7f40ad30ade7ff380ac7b2f2.jpg 0.108\n",
      "666 df9babc2eb670ff5c1a8198467627d7686bceddae1bf1ec63d55099ca0527300.jpg 0.184\n",
      "704 cfbf3f89f64340a77e25ab639f7653506e47a24e17eb68dd90150c6e50eed5ce.jpg 0.978\n",
      "846 9c5c103755f342c3f63b65a85e50907644f2fc97770e54c967f757656116b93c.jpg 0.365\n",
      "906 bd97f007283d09f7d2f700959bbefc93ec9e0ac88fac0e13a7103595f6d01c5e.jpg 0.999\n",
      "921 9f6b7f555545fb0b55c389a6c1f80256cbbb54d2dc8852fe3f945b7ff80b8158.jpg 0.219\n",
      "922 6de4f321d95f380387d7f0bb9c8e75c7a740e1148901458329bd5b7d8064202d.jpg 0.141\n",
      "972 ec8427e14f909e5cde51e269e11a1aae58cf869429938c3cbba319c47577693f.jpg 0.291\n",
      "1069 6dc5577f0af4763dbb5f5ac48cb51c01174be29fb8e81ccd7d49426a554a6dca.jpg 0.934\n",
      "1085 bf882ca8d89b4e9c8a78ac42d1f2fb2db74ee0dcdc02ef69a90837521597d2f0.jpg 0.432\n",
      "1112 0e38a607b7f2d62c2b7d137242e0a36231a7399723289c16740b18ce650f9bc0.jpg 0.107\n",
      "1129 b284a8697b9cd3882a2560f5348fefe704ec9754f9b4bc6acda41ee57ea27b26.jpg 0.438\n",
      "1142 5157eb479faf15c05f960deb4b4597219d6a5912cd82bb591f638c5d8ddf0283.jpg 0.136\n",
      "1157 88603c3fa3e108eaab366dd6901399cb4261ed2deb4835d73de206a5870304cb.jpg 0.343\n",
      "1175 6176afc9919e8f04b4439b515a5d4a9ad4d2be1f6f67d5678a1eff5290b20ce2.jpg 0.439\n",
      "1193 1f2eb7c494f4dcfd9ac161096598972ca7a76f83a893af50daedd28a5cc6ba6b.jpg 0.12\n",
      "1203 686ef501b908e59fa83d10f362fd62bae7dd3739e881ae0180434c6a018838b6.jpg 0.879\n",
      "1248 93d55cce28ac65664e92437dcf8285b9ae0d5e7eb9b5e75ceddb58a5c82d6ea2.jpg 0.454\n",
      "1268 fbf9a477dd5bbda21abfed81a70d91e46c4d36b7de8f010b3633a408282c5df1.jpg 0.809\n",
      "1277 38a1bed2cea80debbf7bb278e1bd9d8f4d6cc8f695abae39ba09e1b711b6630e.jpg 0.985\n",
      "1290 028c7050f7a8dca04777715d3bbedf8d558dd6ecfe74207355e9931e0f06a277.jpg 0.999\n",
      "1298 08a2bcf301ecaf2431e0877f17a4b6fcd4afc750af49b3b7b3971c000adf6278.jpg 0.957\n",
      "1351 bb8a13e6cf9924b672f0c7eb676fdc8821b6dea20ace38b87264203eb101b5f1.jpg 0.18\n",
      "1367 d80514cbd966c2488e30538e98307189db0954911b475928860c710477dc9f72.jpg 0.993\n",
      "1397 3fe5eae23ce209b99d8e2c26e1086281f0f94689f079c4bdce23cc628168ceda.jpg 1.0\n",
      "1446 ffbe2423fbb9c28c09fef66468f098000a3ce6eea59aead1589476ae2a9ca591.jpg 0.999\n",
      "1454 307caf7b9884e7bb1079d05dbb2542396b8bc5daaf6d4276b9a632d803eb77b7.jpg 0.437\n",
      "1486 0d5957405aed50524b71b9a1a6ef079e38b81b2e380ab128462b6c5139aa6e7a.jpg 0.208\n",
      "1659 3df5a04f83eb4e71482e04afd6e0f5bf4e362c04fe7f0dd22fda2754beb24049.jpg 0.299\n"
     ]
    }
   ],
   "source": [
    "print(\"false negatives (classified sfw, actually nsfw)\")\n",
    "for i, f in enumerate(os.listdir(\"/home/htriedman/nsfw_data_scraper/data/test/nsfw\")):\n",
    "    if nsfw_preds_rounded[i] == 0:\n",
    "        print(i, f, round(nsfw_preds[i][0], 3))\n",
    "        \n",
    "print(\"\\nfalse positives (classified nsfw, actually sfw)\")\n",
    "for i, f in enumerate(os.listdir(\"/home/htriedman/nsfw_data_scraper/data/test/sfw\")):\n",
    "    if sfw_preds_rounded[i] == 1:\n",
    "        print(i, f, round(sfw_preds[i][0], 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66704c67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
